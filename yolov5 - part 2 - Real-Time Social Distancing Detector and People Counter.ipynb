{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **YOLOv5 - Real-Time Social Distancing Detector and People Counter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.** Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Yolov5\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd ./yolov5\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.** Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\39345/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-7-20 Python-3.9.10 torch-1.11.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Download the pre-trained YOLOv5 model from torch.hub\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.** Inspect the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video\n",
    "cap = cv2.VideoCapture('./Miscellaneous/people.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    # Capture the frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If we correctly captured the frame\n",
    "    if ret == True:\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Original video', frame)\n",
    "\n",
    "        # If we press 'q' then we exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # If we did not capture correctly the frame we exit\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Close everything in the end\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is:\n",
    "\n",
    "![Gif](./Miscellaneous/original.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.** YOLOv5 detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('./Miscellaneous/people.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        \n",
    "        # Make detections\n",
    "        results = model(frame)\n",
    "\n",
    "        # Display\n",
    "        cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is:\n",
    "\n",
    "![Gif](./Miscellaneous/yolov5.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.** Get the average height of the boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display settings\n",
    "red   = (0,0,255)\n",
    "green = (0,255,0)\n",
    "blue  = (255,0,0)\n",
    "black = (0,0,0)\n",
    "white = (255, 255, 255)\n",
    "\n",
    "# Geometric figures settings\n",
    "thickness = 3\n",
    "circle_radius = 6\n",
    "fill = -1 # to fill the geometric figure\n",
    "\n",
    "# Text settings\n",
    "text_thickness = 1\n",
    "text_size = 0.4\n",
    "title_thickness = 2\n",
    "title_size = 1\n",
    "title = 'Real-time social distancing detection system'\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX # or cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture('./Miscellaneous/people.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "\n",
    "        # Let's define a variable to save all the heights\n",
    "        heights = 0\n",
    "\n",
    "        # Predictions\n",
    "        results = model(frame)\n",
    "\n",
    "        # We extract the needed informations: xyxy, xywh\n",
    "        predictions_xyxy = results.pandas().xyxy[0]\n",
    "        predictions_xywh = results.pandas().xywh[0]\n",
    "\n",
    "        # Let us consider only the 'person' label\n",
    "        predictions_xyxy = predictions_xyxy[predictions_xyxy['name']=='person']\n",
    "        predictions_xywh = predictions_xywh[predictions_xywh['name']=='person']\n",
    "\n",
    "        # Let's adjust the indeces (they might be not good since we considered just the 'person' label)\n",
    "        predictions_xyxy.index = range(len(predictions_xyxy))\n",
    "        predictions_xywh.index = range(len(predictions_xywh))\n",
    "\n",
    "        # For every person in the frame:\n",
    "        for n in range(len(predictions_xyxy)):\n",
    "\n",
    "            # Let's add-up the height of the box\n",
    "            heights += predictions_xywh['height'][n]\n",
    "\n",
    "            # Save the coordinates of the box\n",
    "            x_min = int(predictions_xyxy['xmin'][n])\n",
    "            y_min = int(predictions_xyxy['ymin'][n])\n",
    "            x_max = int(predictions_xyxy['xmax'][n])\n",
    "            y_max = int(predictions_xyxy['ymax'][n])\n",
    "\n",
    "            # and the coordinates of the center of each box\n",
    "            x_center = int(predictions_xywh['xcenter'][n])\n",
    "            y_center = int(predictions_xywh['ycenter'][n])\n",
    "\n",
    "            # Let's draw the bounding box\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), red, thickness);\n",
    "            cv2.putText(frame, 'Person', (x_min-3, y_min-5), font, text_size, red, text_thickness);\n",
    "\n",
    "            # and a blue dot to represent the center of the box\n",
    "            cv2.circle(frame, (x_center, y_center), circle_radius, blue, fill)\n",
    "\n",
    "        # Evaluate the average height of the boxes in the current frame\n",
    "        average_height = heights/len(predictions_xyxy)\n",
    "        average_height = 'Average height of boxes ' + str(average_height)\n",
    "\n",
    "        # Print the average height of the boxes\n",
    "        cv2.putText(frame, average_height, (50,50), font, title_size, white, title_thickness);\n",
    "\n",
    "        # Show everything: frame, boxes, centers, average height\n",
    "        cv2.imshow(title, frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is:\n",
    "\n",
    "![Gif](./Miscellaneous/box_heights.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.** Social distancing detector and people counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to determine what will be the minimal distance to be respected.\n",
    "\n",
    "To do this, we need to do some assumptions:\n",
    "* we consider that a person is, on average, 1 meter and 70 cm tall\n",
    "* we consider that a good distance is, about, 1 meter and 30 cm\n",
    "* an (approximate) average of the heights of the boxes is 65\n",
    "\n",
    "That said, let's disregard the three-dimensional geometry of the scene for a moment and let's focus instead on the relation:\n",
    "\n",
    "$\\qquad\\qquad average\\hspace{2pt}human\\hspace{2pt}height\\hspace{2pt}:\\hspace{2pt}minimal\\hspace{2pt}distance\\hspace{2pt}in\\hspace{2pt}reality\\hspace{2pt}=\\hspace{2pt} average\\hspace{2pt}box\\hspace{2pt}height\\hspace{2pt}:\\hspace{2pt}minimal\\hspace{2pt}distance\\hspace{2pt}between\\hspace{2pt}points$\n",
    "\n",
    "So that, we can calculate the $minimal\\hspace{2pt}distance\\hspace{2pt}between\\hspace{2pt}points$ as:\n",
    "\n",
    "$\\qquad\\qquad minimal\\hspace{2pt}distance\\hspace{2pt}between\\hspace{2pt}points = average\\hspace{2pt}box\\hspace{2pt}height\\hspace{2pt}\\cdot\\hspace{2pt}\\frac{minimal\\hspace{2pt}distance\\hspace{2pt}in\\hspace{2pt}reality}{average\\hspace{2pt}human\\hspace{2pt}height}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimal distance between two centers in the frame has to be:  49.705882352941174\n"
     ]
    }
   ],
   "source": [
    "average_box_height = 65\n",
    "average_human_height = 170 #cm\n",
    "minimal_distance_in_reality = 130 #cm\n",
    "minimal_distance_between_points = (average_box_height * minimal_distance_in_reality)/average_human_height\n",
    "\n",
    "print('The minimal distance between two centers in the frame has to be: ', minimal_distance_between_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display settings\n",
    "red   = (0,0,255)\n",
    "green = (0,255,0)\n",
    "blue  = (255,0,0)\n",
    "black = (0,0,0)\n",
    "white = (255, 255, 255)\n",
    "\n",
    "# Geometric figures settings\n",
    "thickness = 3\n",
    "circle_radius = 6\n",
    "fill = -1 # to fill the geometric figure\n",
    "\n",
    "# Text settings\n",
    "text_thickness = 1\n",
    "text_size = 0.4\n",
    "title_thickness = 2\n",
    "title_size = 1\n",
    "title = 'Real-time social distancing detection system'\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX # or cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "cap = cv2.VideoCapture('./Miscellaneous/people.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "\n",
    "        # Predictions\n",
    "        results = model(frame)\n",
    "\n",
    "        # We extract the needed informations: xyxy, xywh\n",
    "        predictions_xyxy = results.pandas().xyxy[0]\n",
    "        predictions_xywh = results.pandas().xywh[0]\n",
    "\n",
    "        # Let us consider only the 'person' label\n",
    "        predictions_xyxy = predictions_xyxy[predictions_xyxy['name']=='person']\n",
    "        predictions_xywh = predictions_xywh[predictions_xywh['name']=='person']\n",
    "\n",
    "        #  Let's adjust the indeces (they might be not good since we considered just the 'person' label)\n",
    "        predictions_xyxy.index = range(len(predictions_xyxy))\n",
    "        predictions_xywh.index = range(len(predictions_xywh))\n",
    "\n",
    "        # In this vector we will save (with 1's) the elements for which we want to make red boxes\n",
    "        colori_box = [0] * len(predictions_xyxy)\n",
    "        \n",
    "        # For every person in the frame:\n",
    "        for n in range(len(predictions_xyxy)):\n",
    "\n",
    "                # n-th person's box center coordinates\n",
    "                x_center = int(predictions_xywh['xcenter'][n])\n",
    "                y_center = int(predictions_xywh['ycenter'][n])\n",
    "\n",
    "                # For each person, we create a vector of distances w.r.t. all other people\n",
    "                # e.g. for person number 0, two vectors will be created:\n",
    "                #           distances = [5, 5, 2]\n",
    "                #           distances_indeces = [1, 2, 3]\n",
    "                #      which means that the person closest to person 0 is person 3\n",
    "\n",
    "                distances = []\n",
    "                distances_indeces = []\n",
    "\n",
    "                for m in range(len(predictions_xyxy)):\n",
    "                    if m != n:\n",
    "                        x_center_m = int(predictions_xywh['xcenter'][m])\n",
    "                        y_center_m = int(predictions_xywh['ycenter'][m])\n",
    "                        centers_distance = math.dist((x_center, y_center), (x_center_m, y_center_m))\n",
    "                        distances.append(centers_distance)\n",
    "                        distances_indeces.append(m)\n",
    "\n",
    "                # Calculate now the minimum distance (in the above example is 2)\n",
    "                minimal_distance = np.min(distances)\n",
    "                # and the index of the minimum distance element (in the example above is 3)\n",
    "                minimal_distance_element = distances_indeces[np.argmin(distances)]\n",
    "\n",
    "                # If the two people (the two centers) are too close then both will be assigned flags = 1 in 'colors_box'\n",
    "                if minimal_distance < minimal_distance_between_points:\n",
    "                    if colori_box[n] == 0:\n",
    "                        colori_box[n] = 1\n",
    "                    if colori_box[minimal_distance_element] == 0:\n",
    "                        colori_box[minimal_distance_element] = 1\n",
    "\n",
    "        # Once defined the vector 'colors_box', let's print\n",
    "        for n in range(len(predictions_xyxy)):\n",
    "            x_min = int(predictions_xyxy['xmin'][n])\n",
    "            y_min = int(predictions_xyxy['ymin'][n])\n",
    "            x_max = int(predictions_xyxy['xmax'][n])\n",
    "            y_max = int(predictions_xyxy['ymax'][n])\n",
    "\n",
    "            if colori_box[n] == 1:\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), red, thickness);\n",
    "                cv2.putText(frame, 'Person', (x_min-3, y_min-5), font, text_size, red, text_thickness);\n",
    "            else:\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), green, thickness);\n",
    "                cv2.putText(frame, 'Person', (x_min-3, y_min-5), font, text_size, green, text_thickness);\n",
    "\n",
    "            # Also, we always print the center of the box in blue\n",
    "            x_center = int(predictions_xywh['xcenter'][n])\n",
    "            y_center = int(predictions_xywh['ycenter'][n])\n",
    "            cv2.circle(frame, (x_center, y_center), circle_radius, blue, fill)\n",
    "\n",
    "        # People counter\n",
    "        people_counter = 'Number of people ' + str(len(predictions_xyxy))\n",
    "        cv2.putText(frame, people_counter, (50,50), font, title_size, white, title_thickness);\n",
    "\n",
    "        # Plot all\n",
    "        cv2.imshow(title, frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is:\n",
    "\n",
    "![Gif](./Miscellaneous/final.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9805bccb659ffcb6952b8b29440036fac091f8170d71a5a402ad9a8f2988209f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
